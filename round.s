// Code generated by command: go run main.go. DO NOT EDIT.

#include "textflag.h"

DATA rot16_shuf<>+0(SB)/1, $0x02
DATA rot16_shuf<>+1(SB)/1, $0x03
DATA rot16_shuf<>+2(SB)/1, $0x00
DATA rot16_shuf<>+3(SB)/1, $0x01
DATA rot16_shuf<>+4(SB)/1, $0x06
DATA rot16_shuf<>+5(SB)/1, $0x07
DATA rot16_shuf<>+6(SB)/1, $0x04
DATA rot16_shuf<>+7(SB)/1, $0x05
DATA rot16_shuf<>+8(SB)/1, $0x0a
DATA rot16_shuf<>+9(SB)/1, $0x0b
DATA rot16_shuf<>+10(SB)/1, $0x08
DATA rot16_shuf<>+11(SB)/1, $0x09
DATA rot16_shuf<>+12(SB)/1, $0x0e
DATA rot16_shuf<>+13(SB)/1, $0x0f
DATA rot16_shuf<>+14(SB)/1, $0x0c
DATA rot16_shuf<>+15(SB)/1, $0x0d
DATA rot16_shuf<>+16(SB)/1, $0x12
DATA rot16_shuf<>+17(SB)/1, $0x13
DATA rot16_shuf<>+18(SB)/1, $0x10
DATA rot16_shuf<>+19(SB)/1, $0x11
DATA rot16_shuf<>+20(SB)/1, $0x16
DATA rot16_shuf<>+21(SB)/1, $0x17
DATA rot16_shuf<>+22(SB)/1, $0x14
DATA rot16_shuf<>+23(SB)/1, $0x15
DATA rot16_shuf<>+24(SB)/1, $0x1a
DATA rot16_shuf<>+25(SB)/1, $0x1b
DATA rot16_shuf<>+26(SB)/1, $0x18
DATA rot16_shuf<>+27(SB)/1, $0x19
DATA rot16_shuf<>+28(SB)/1, $0x1e
DATA rot16_shuf<>+29(SB)/1, $0x1f
DATA rot16_shuf<>+30(SB)/1, $0x1c
DATA rot16_shuf<>+31(SB)/1, $0x1d
GLOBL rot16_shuf<>(SB), RODATA|NOPTR, $32

DATA rot8_shuf<>+0(SB)/1, $0x01
DATA rot8_shuf<>+1(SB)/1, $0x02
DATA rot8_shuf<>+2(SB)/1, $0x03
DATA rot8_shuf<>+3(SB)/1, $0x00
DATA rot8_shuf<>+4(SB)/1, $0x05
DATA rot8_shuf<>+5(SB)/1, $0x06
DATA rot8_shuf<>+6(SB)/1, $0x07
DATA rot8_shuf<>+7(SB)/1, $0x04
DATA rot8_shuf<>+8(SB)/1, $0x09
DATA rot8_shuf<>+9(SB)/1, $0x0a
DATA rot8_shuf<>+10(SB)/1, $0x0b
DATA rot8_shuf<>+11(SB)/1, $0x08
DATA rot8_shuf<>+12(SB)/1, $0x0d
DATA rot8_shuf<>+13(SB)/1, $0x0e
DATA rot8_shuf<>+14(SB)/1, $0x0f
DATA rot8_shuf<>+15(SB)/1, $0x0c
DATA rot8_shuf<>+16(SB)/1, $0x11
DATA rot8_shuf<>+17(SB)/1, $0x12
DATA rot8_shuf<>+18(SB)/1, $0x13
DATA rot8_shuf<>+19(SB)/1, $0x10
DATA rot8_shuf<>+20(SB)/1, $0x15
DATA rot8_shuf<>+21(SB)/1, $0x16
DATA rot8_shuf<>+22(SB)/1, $0x17
DATA rot8_shuf<>+23(SB)/1, $0x14
DATA rot8_shuf<>+24(SB)/1, $0x19
DATA rot8_shuf<>+25(SB)/1, $0x1a
DATA rot8_shuf<>+26(SB)/1, $0x1b
DATA rot8_shuf<>+27(SB)/1, $0x18
DATA rot8_shuf<>+28(SB)/1, $0x1d
DATA rot8_shuf<>+29(SB)/1, $0x1e
DATA rot8_shuf<>+30(SB)/1, $0x1f
DATA rot8_shuf<>+31(SB)/1, $0x1c
GLOBL rot8_shuf<>(SB), RODATA|NOPTR, $32

// func hash8_avx(inputs *[8]*byte, blocks int, key *[8]uint32, counter uint64, inc uint64, flags uint8, flags_start uint8, flags_end uint8, out *[256]byte, v *[16][8]uint32, m *[16][8]uint32)
// Requires: AVX, AVX2
TEXT Â·hash8_avx(SB), NOSPLIT, $32-72
	MOVQ    v+56(FP), AX
	MOVQ    m+64(FP), CX
	VMOVDQU (AX), Y0
	VMOVDQU 32(AX), Y1
	VMOVDQU 64(AX), Y2
	VMOVDQU 96(AX), Y3
	VMOVDQU 128(AX), Y4
	VMOVDQU 160(AX), Y5
	VMOVDQU 192(AX), Y6
	VMOVDQU 224(AX), Y7
	VMOVDQU 256(AX), Y8
	VMOVDQU 288(AX), Y9
	VMOVDQU 320(AX), Y10
	VMOVDQU 352(AX), Y11
	VMOVDQU 384(AX), Y12
	VMOVDQU 416(AX), Y13
	VMOVDQU 448(AX), Y14
	VMOVDQU 480(AX), Y15
	VPADDD  (CX), Y0, Y0
	VPADDD  64(CX), Y1, Y1
	VPADDD  128(CX), Y2, Y2
	VPADDD  192(CX), Y3, Y3
	VPADDD  Y4, Y0, Y0
	VPADDD  Y5, Y1, Y1
	VPADDD  Y6, Y2, Y2
	VPADDD  Y7, Y3, Y3
	VPXOR   Y0, Y12, Y12
	VPXOR   Y1, Y13, Y13
	VPXOR   Y2, Y14, Y14
	VPXOR   Y3, Y15, Y15
	VPSHUFB rot16_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot16_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot16_shuf<>+0(SB), Y14, Y14
	VPSHUFB rot16_shuf<>+0(SB), Y15, Y15
	VPADDD  Y12, Y8, Y8
	VPADDD  Y13, Y9, Y9
	VPADDD  Y14, Y10, Y10
	VPADDD  Y15, Y11, Y11
	VPXOR   Y8, Y4, Y4
	VPXOR   Y9, Y5, Y5
	VPXOR   Y10, Y6, Y6
	VPXOR   Y11, Y7, Y7
	VMOVDQU Y0, (SP)
	VPSRLD  $0x0c, Y4, Y0
	VPSLLD  $0x14, Y4, Y4
	VPOR    Y0, Y4, Y0
	VPSRLD  $0x0c, Y5, Y4
	VPSLLD  $0x14, Y5, Y5
	VPOR    Y4, Y5, Y4
	VPSRLD  $0x0c, Y6, Y5
	VPSLLD  $0x14, Y6, Y6
	VPOR    Y5, Y6, Y5
	VPSRLD  $0x0c, Y7, Y6
	VPSLLD  $0x14, Y7, Y7
	VPOR    Y6, Y7, Y6
	VMOVDQU (SP), Y7
	VPADDD  32(CX), Y7, Y7
	VPADDD  96(CX), Y1, Y1
	VPADDD  160(CX), Y2, Y2
	VPADDD  224(CX), Y3, Y3
	VPADDD  Y0, Y7, Y7
	VPADDD  Y4, Y1, Y1
	VPADDD  Y5, Y2, Y2
	VPADDD  Y6, Y3, Y3
	VPXOR   Y7, Y12, Y12
	VPXOR   Y1, Y13, Y13
	VPXOR   Y2, Y14, Y14
	VPXOR   Y3, Y15, Y15
	VPSHUFB rot8_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot8_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot8_shuf<>+0(SB), Y14, Y14
	VPSHUFB rot8_shuf<>+0(SB), Y15, Y15
	VPADDD  Y12, Y8, Y8
	VPADDD  Y13, Y9, Y9
	VPADDD  Y14, Y10, Y10
	VPADDD  Y15, Y11, Y11
	VPXOR   Y8, Y0, Y0
	VPXOR   Y9, Y4, Y4
	VPXOR   Y10, Y5, Y5
	VPXOR   Y11, Y6, Y6
	VMOVDQU Y7, (SP)
	VPSRLD  $0x07, Y0, Y7
	VPSLLD  $0x19, Y0, Y0
	VPOR    Y7, Y0, Y0
	VPSRLD  $0x07, Y4, Y7
	VPSLLD  $0x19, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x07, Y5, Y7
	VPSLLD  $0x19, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x07, Y6, Y7
	VPSLLD  $0x19, Y6, Y6
	VPOR    Y7, Y6, Y6
	VMOVDQU (SP), Y7
	VPADDD  256(CX), Y7, Y7
	VPADDD  320(CX), Y1, Y1
	VPADDD  384(CX), Y2, Y2
	VPADDD  448(CX), Y3, Y3
	VPADDD  Y4, Y7, Y7
	VPADDD  Y5, Y1, Y1
	VPADDD  Y6, Y2, Y2
	VPADDD  Y0, Y3, Y3
	VPXOR   Y7, Y15, Y15
	VPXOR   Y1, Y12, Y12
	VPXOR   Y2, Y13, Y13
	VPXOR   Y3, Y14, Y14
	VPSHUFB rot16_shuf<>+0(SB), Y15, Y15
	VPSHUFB rot16_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot16_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot16_shuf<>+0(SB), Y14, Y14
	VPADDD  Y15, Y10, Y10
	VPADDD  Y12, Y11, Y11
	VPADDD  Y13, Y8, Y8
	VPADDD  Y14, Y9, Y9
	VPXOR   Y10, Y4, Y4
	VPXOR   Y11, Y5, Y5
	VPXOR   Y8, Y6, Y6
	VPXOR   Y9, Y0, Y0
	VMOVDQU Y7, (SP)
	VPSRLD  $0x0c, Y4, Y7
	VPSLLD  $0x14, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x0c, Y5, Y7
	VPSLLD  $0x14, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x0c, Y6, Y7
	VPSLLD  $0x14, Y6, Y6
	VPOR    Y7, Y6, Y6
	VPSRLD  $0x0c, Y0, Y7
	VPSLLD  $0x14, Y0, Y0
	VPOR    Y7, Y0, Y0
	VMOVDQU (SP), Y7
	VPADDD  288(CX), Y7, Y7
	VPADDD  352(CX), Y1, Y1
	VPADDD  416(CX), Y2, Y2
	VPADDD  480(CX), Y3, Y3
	VPADDD  Y4, Y7, Y7
	VPADDD  Y5, Y1, Y1
	VPADDD  Y6, Y2, Y2
	VPADDD  Y0, Y3, Y3
	VPXOR   Y7, Y15, Y15
	VPXOR   Y1, Y12, Y12
	VPXOR   Y2, Y13, Y13
	VPXOR   Y3, Y14, Y14
	VPSHUFB rot8_shuf<>+0(SB), Y15, Y15
	VPSHUFB rot8_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot8_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot8_shuf<>+0(SB), Y14, Y14
	VPADDD  Y15, Y10, Y10
	VPADDD  Y12, Y11, Y11
	VPADDD  Y13, Y8, Y8
	VPADDD  Y14, Y9, Y9
	VPXOR   Y10, Y4, Y4
	VPXOR   Y11, Y5, Y5
	VPXOR   Y8, Y6, Y6
	VPXOR   Y9, Y0, Y0
	VMOVDQU Y7, (SP)
	VPSRLD  $0x07, Y4, Y7
	VPSLLD  $0x19, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x07, Y5, Y7
	VPSLLD  $0x19, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x07, Y6, Y7
	VPSLLD  $0x19, Y6, Y6
	VPOR    Y7, Y6, Y6
	VPSRLD  $0x07, Y0, Y7
	VPSLLD  $0x19, Y0, Y0
	VPOR    Y7, Y0, Y0
	VMOVDQU (SP), Y7
	VPADDD  64(CX), Y7, Y7
	VPADDD  96(CX), Y1, Y1
	VPADDD  224(CX), Y2, Y2
	VPADDD  128(CX), Y3, Y3
	VPADDD  Y0, Y7, Y7
	VPADDD  Y4, Y1, Y1
	VPADDD  Y5, Y2, Y2
	VPADDD  Y6, Y3, Y3
	VPXOR   Y7, Y12, Y12
	VPXOR   Y1, Y13, Y13
	VPXOR   Y2, Y14, Y14
	VPXOR   Y3, Y15, Y15
	VPSHUFB rot16_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot16_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot16_shuf<>+0(SB), Y14, Y14
	VPSHUFB rot16_shuf<>+0(SB), Y15, Y15
	VPADDD  Y12, Y8, Y8
	VPADDD  Y13, Y9, Y9
	VPADDD  Y14, Y10, Y10
	VPADDD  Y15, Y11, Y11
	VPXOR   Y8, Y0, Y0
	VPXOR   Y9, Y4, Y4
	VPXOR   Y10, Y5, Y5
	VPXOR   Y11, Y6, Y6
	VMOVDQU Y7, (SP)
	VPSRLD  $0x0c, Y0, Y7
	VPSLLD  $0x14, Y0, Y0
	VPOR    Y7, Y0, Y0
	VPSRLD  $0x0c, Y4, Y7
	VPSLLD  $0x14, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x0c, Y5, Y7
	VPSLLD  $0x14, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x0c, Y6, Y7
	VPSLLD  $0x14, Y6, Y6
	VPOR    Y7, Y6, Y6
	VMOVDQU (SP), Y7
	VPADDD  192(CX), Y7, Y7
	VPADDD  320(CX), Y1, Y1
	VPADDD  (CX), Y2, Y2
	VPADDD  416(CX), Y3, Y3
	VPADDD  Y0, Y7, Y7
	VPADDD  Y4, Y1, Y1
	VPADDD  Y5, Y2, Y2
	VPADDD  Y6, Y3, Y3
	VPXOR   Y7, Y12, Y12
	VPXOR   Y1, Y13, Y13
	VPXOR   Y2, Y14, Y14
	VPXOR   Y3, Y15, Y15
	VPSHUFB rot8_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot8_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot8_shuf<>+0(SB), Y14, Y14
	VPSHUFB rot8_shuf<>+0(SB), Y15, Y15
	VPADDD  Y12, Y8, Y8
	VPADDD  Y13, Y9, Y9
	VPADDD  Y14, Y10, Y10
	VPADDD  Y15, Y11, Y11
	VPXOR   Y8, Y0, Y0
	VPXOR   Y9, Y4, Y4
	VPXOR   Y10, Y5, Y5
	VPXOR   Y11, Y6, Y6
	VMOVDQU Y7, (SP)
	VPSRLD  $0x07, Y0, Y7
	VPSLLD  $0x19, Y0, Y0
	VPOR    Y7, Y0, Y0
	VPSRLD  $0x07, Y4, Y7
	VPSLLD  $0x19, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x07, Y5, Y7
	VPSLLD  $0x19, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x07, Y6, Y7
	VPSLLD  $0x19, Y6, Y6
	VPOR    Y7, Y6, Y6
	VMOVDQU (SP), Y7
	VPADDD  32(CX), Y7, Y7
	VPADDD  384(CX), Y1, Y1
	VPADDD  288(CX), Y2, Y2
	VPADDD  480(CX), Y3, Y3
	VPADDD  Y4, Y7, Y7
	VPADDD  Y5, Y1, Y1
	VPADDD  Y6, Y2, Y2
	VPADDD  Y0, Y3, Y3
	VPXOR   Y7, Y15, Y15
	VPXOR   Y1, Y12, Y12
	VPXOR   Y2, Y13, Y13
	VPXOR   Y3, Y14, Y14
	VPSHUFB rot16_shuf<>+0(SB), Y15, Y15
	VPSHUFB rot16_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot16_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot16_shuf<>+0(SB), Y14, Y14
	VPADDD  Y15, Y10, Y10
	VPADDD  Y12, Y11, Y11
	VPADDD  Y13, Y8, Y8
	VPADDD  Y14, Y9, Y9
	VPXOR   Y10, Y4, Y4
	VPXOR   Y11, Y5, Y5
	VPXOR   Y8, Y6, Y6
	VPXOR   Y9, Y0, Y0
	VMOVDQU Y7, (SP)
	VPSRLD  $0x0c, Y4, Y7
	VPSLLD  $0x14, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x0c, Y5, Y7
	VPSLLD  $0x14, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x0c, Y6, Y7
	VPSLLD  $0x14, Y6, Y6
	VPOR    Y7, Y6, Y6
	VPSRLD  $0x0c, Y0, Y7
	VPSLLD  $0x14, Y0, Y0
	VPOR    Y7, Y0, Y0
	VMOVDQU (SP), Y7
	VPADDD  352(CX), Y7, Y7
	VPADDD  160(CX), Y1, Y1
	VPADDD  448(CX), Y2, Y2
	VPADDD  256(CX), Y3, Y3
	VPADDD  Y4, Y7, Y7
	VPADDD  Y5, Y1, Y1
	VPADDD  Y6, Y2, Y2
	VPADDD  Y0, Y3, Y3
	VPXOR   Y7, Y15, Y15
	VPXOR   Y1, Y12, Y12
	VPXOR   Y2, Y13, Y13
	VPXOR   Y3, Y14, Y14
	VPSHUFB rot8_shuf<>+0(SB), Y15, Y15
	VPSHUFB rot8_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot8_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot8_shuf<>+0(SB), Y14, Y14
	VPADDD  Y15, Y10, Y10
	VPADDD  Y12, Y11, Y11
	VPADDD  Y13, Y8, Y8
	VPADDD  Y14, Y9, Y9
	VPXOR   Y10, Y4, Y4
	VPXOR   Y11, Y5, Y5
	VPXOR   Y8, Y6, Y6
	VPXOR   Y9, Y0, Y0
	VMOVDQU Y7, (SP)
	VPSRLD  $0x07, Y4, Y7
	VPSLLD  $0x19, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x07, Y5, Y7
	VPSLLD  $0x19, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x07, Y6, Y7
	VPSLLD  $0x19, Y6, Y6
	VPOR    Y7, Y6, Y6
	VPSRLD  $0x07, Y0, Y7
	VPSLLD  $0x19, Y0, Y0
	VPOR    Y7, Y0, Y0
	VMOVDQU (SP), Y7
	VPADDD  96(CX), Y7, Y7
	VPADDD  320(CX), Y1, Y1
	VPADDD  416(CX), Y2, Y2
	VPADDD  224(CX), Y3, Y3
	VPADDD  Y0, Y7, Y7
	VPADDD  Y4, Y1, Y1
	VPADDD  Y5, Y2, Y2
	VPADDD  Y6, Y3, Y3
	VPXOR   Y7, Y12, Y12
	VPXOR   Y1, Y13, Y13
	VPXOR   Y2, Y14, Y14
	VPXOR   Y3, Y15, Y15
	VPSHUFB rot16_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot16_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot16_shuf<>+0(SB), Y14, Y14
	VPSHUFB rot16_shuf<>+0(SB), Y15, Y15
	VPADDD  Y12, Y8, Y8
	VPADDD  Y13, Y9, Y9
	VPADDD  Y14, Y10, Y10
	VPADDD  Y15, Y11, Y11
	VPXOR   Y8, Y0, Y0
	VPXOR   Y9, Y4, Y4
	VPXOR   Y10, Y5, Y5
	VPXOR   Y11, Y6, Y6
	VMOVDQU Y7, (SP)
	VPSRLD  $0x0c, Y0, Y7
	VPSLLD  $0x14, Y0, Y0
	VPOR    Y7, Y0, Y0
	VPSRLD  $0x0c, Y4, Y7
	VPSLLD  $0x14, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x0c, Y5, Y7
	VPSLLD  $0x14, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x0c, Y6, Y7
	VPSLLD  $0x14, Y6, Y6
	VPOR    Y7, Y6, Y6
	VMOVDQU (SP), Y7
	VPADDD  128(CX), Y7, Y7
	VPADDD  384(CX), Y1, Y1
	VPADDD  64(CX), Y2, Y2
	VPADDD  448(CX), Y3, Y3
	VPADDD  Y0, Y7, Y7
	VPADDD  Y4, Y1, Y1
	VPADDD  Y5, Y2, Y2
	VPADDD  Y6, Y3, Y3
	VPXOR   Y7, Y12, Y12
	VPXOR   Y1, Y13, Y13
	VPXOR   Y2, Y14, Y14
	VPXOR   Y3, Y15, Y15
	VPSHUFB rot8_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot8_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot8_shuf<>+0(SB), Y14, Y14
	VPSHUFB rot8_shuf<>+0(SB), Y15, Y15
	VPADDD  Y12, Y8, Y8
	VPADDD  Y13, Y9, Y9
	VPADDD  Y14, Y10, Y10
	VPADDD  Y15, Y11, Y11
	VPXOR   Y8, Y0, Y0
	VPXOR   Y9, Y4, Y4
	VPXOR   Y10, Y5, Y5
	VPXOR   Y11, Y6, Y6
	VMOVDQU Y7, (SP)
	VPSRLD  $0x07, Y0, Y7
	VPSLLD  $0x19, Y0, Y0
	VPOR    Y7, Y0, Y0
	VPSRLD  $0x07, Y4, Y7
	VPSLLD  $0x19, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x07, Y5, Y7
	VPSLLD  $0x19, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x07, Y6, Y7
	VPSLLD  $0x19, Y6, Y6
	VPOR    Y7, Y6, Y6
	VMOVDQU (SP), Y7
	VPADDD  192(CX), Y7, Y7
	VPADDD  288(CX), Y1, Y1
	VPADDD  352(CX), Y2, Y2
	VPADDD  256(CX), Y3, Y3
	VPADDD  Y4, Y7, Y7
	VPADDD  Y5, Y1, Y1
	VPADDD  Y6, Y2, Y2
	VPADDD  Y0, Y3, Y3
	VPXOR   Y7, Y15, Y15
	VPXOR   Y1, Y12, Y12
	VPXOR   Y2, Y13, Y13
	VPXOR   Y3, Y14, Y14
	VPSHUFB rot16_shuf<>+0(SB), Y15, Y15
	VPSHUFB rot16_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot16_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot16_shuf<>+0(SB), Y14, Y14
	VPADDD  Y15, Y10, Y10
	VPADDD  Y12, Y11, Y11
	VPADDD  Y13, Y8, Y8
	VPADDD  Y14, Y9, Y9
	VPXOR   Y10, Y4, Y4
	VPXOR   Y11, Y5, Y5
	VPXOR   Y8, Y6, Y6
	VPXOR   Y9, Y0, Y0
	VMOVDQU Y7, (SP)
	VPSRLD  $0x0c, Y4, Y7
	VPSLLD  $0x14, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x0c, Y5, Y7
	VPSLLD  $0x14, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x0c, Y6, Y7
	VPSLLD  $0x14, Y6, Y6
	VPOR    Y7, Y6, Y6
	VPSRLD  $0x0c, Y0, Y7
	VPSLLD  $0x14, Y0, Y0
	VPOR    Y7, Y0, Y0
	VMOVDQU (SP), Y7
	VPADDD  160(CX), Y7, Y7
	VPADDD  (CX), Y1, Y1
	VPADDD  480(CX), Y2, Y2
	VPADDD  32(CX), Y3, Y3
	VPADDD  Y4, Y7, Y7
	VPADDD  Y5, Y1, Y1
	VPADDD  Y6, Y2, Y2
	VPADDD  Y0, Y3, Y3
	VPXOR   Y7, Y15, Y15
	VPXOR   Y1, Y12, Y12
	VPXOR   Y2, Y13, Y13
	VPXOR   Y3, Y14, Y14
	VPSHUFB rot8_shuf<>+0(SB), Y15, Y15
	VPSHUFB rot8_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot8_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot8_shuf<>+0(SB), Y14, Y14
	VPADDD  Y15, Y10, Y10
	VPADDD  Y12, Y11, Y11
	VPADDD  Y13, Y8, Y8
	VPADDD  Y14, Y9, Y9
	VPXOR   Y10, Y4, Y4
	VPXOR   Y11, Y5, Y5
	VPXOR   Y8, Y6, Y6
	VPXOR   Y9, Y0, Y0
	VMOVDQU Y7, (SP)
	VPSRLD  $0x07, Y4, Y7
	VPSLLD  $0x19, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x07, Y5, Y7
	VPSLLD  $0x19, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x07, Y6, Y7
	VPSLLD  $0x19, Y6, Y6
	VPOR    Y7, Y6, Y6
	VPSRLD  $0x07, Y0, Y7
	VPSLLD  $0x19, Y0, Y0
	VPOR    Y7, Y0, Y0
	VMOVDQU (SP), Y7
	VPADDD  320(CX), Y7, Y7
	VPADDD  384(CX), Y1, Y1
	VPADDD  448(CX), Y2, Y2
	VPADDD  416(CX), Y3, Y3
	VPADDD  Y0, Y7, Y7
	VPADDD  Y4, Y1, Y1
	VPADDD  Y5, Y2, Y2
	VPADDD  Y6, Y3, Y3
	VPXOR   Y7, Y12, Y12
	VPXOR   Y1, Y13, Y13
	VPXOR   Y2, Y14, Y14
	VPXOR   Y3, Y15, Y15
	VPSHUFB rot16_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot16_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot16_shuf<>+0(SB), Y14, Y14
	VPSHUFB rot16_shuf<>+0(SB), Y15, Y15
	VPADDD  Y12, Y8, Y8
	VPADDD  Y13, Y9, Y9
	VPADDD  Y14, Y10, Y10
	VPADDD  Y15, Y11, Y11
	VPXOR   Y8, Y0, Y0
	VPXOR   Y9, Y4, Y4
	VPXOR   Y10, Y5, Y5
	VPXOR   Y11, Y6, Y6
	VMOVDQU Y7, (SP)
	VPSRLD  $0x0c, Y0, Y7
	VPSLLD  $0x14, Y0, Y0
	VPOR    Y7, Y0, Y0
	VPSRLD  $0x0c, Y4, Y7
	VPSLLD  $0x14, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x0c, Y5, Y7
	VPSLLD  $0x14, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x0c, Y6, Y7
	VPSLLD  $0x14, Y6, Y6
	VPOR    Y7, Y6, Y6
	VMOVDQU (SP), Y7
	VPADDD  224(CX), Y7, Y7
	VPADDD  288(CX), Y1, Y1
	VPADDD  96(CX), Y2, Y2
	VPADDD  480(CX), Y3, Y3
	VPADDD  Y0, Y7, Y7
	VPADDD  Y4, Y1, Y1
	VPADDD  Y5, Y2, Y2
	VPADDD  Y6, Y3, Y3
	VPXOR   Y7, Y12, Y12
	VPXOR   Y1, Y13, Y13
	VPXOR   Y2, Y14, Y14
	VPXOR   Y3, Y15, Y15
	VPSHUFB rot8_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot8_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot8_shuf<>+0(SB), Y14, Y14
	VPSHUFB rot8_shuf<>+0(SB), Y15, Y15
	VPADDD  Y12, Y8, Y8
	VPADDD  Y13, Y9, Y9
	VPADDD  Y14, Y10, Y10
	VPADDD  Y15, Y11, Y11
	VPXOR   Y8, Y0, Y0
	VPXOR   Y9, Y4, Y4
	VPXOR   Y10, Y5, Y5
	VPXOR   Y11, Y6, Y6
	VMOVDQU Y7, (SP)
	VPSRLD  $0x07, Y0, Y7
	VPSLLD  $0x19, Y0, Y0
	VPOR    Y7, Y0, Y0
	VPSRLD  $0x07, Y4, Y7
	VPSLLD  $0x19, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x07, Y5, Y7
	VPSLLD  $0x19, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x07, Y6, Y7
	VPSLLD  $0x19, Y6, Y6
	VPOR    Y7, Y6, Y6
	VMOVDQU (SP), Y7
	VPADDD  128(CX), Y7, Y7
	VPADDD  352(CX), Y1, Y1
	VPADDD  160(CX), Y2, Y2
	VPADDD  32(CX), Y3, Y3
	VPADDD  Y4, Y7, Y7
	VPADDD  Y5, Y1, Y1
	VPADDD  Y6, Y2, Y2
	VPADDD  Y0, Y3, Y3
	VPXOR   Y7, Y15, Y15
	VPXOR   Y1, Y12, Y12
	VPXOR   Y2, Y13, Y13
	VPXOR   Y3, Y14, Y14
	VPSHUFB rot16_shuf<>+0(SB), Y15, Y15
	VPSHUFB rot16_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot16_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot16_shuf<>+0(SB), Y14, Y14
	VPADDD  Y15, Y10, Y10
	VPADDD  Y12, Y11, Y11
	VPADDD  Y13, Y8, Y8
	VPADDD  Y14, Y9, Y9
	VPXOR   Y10, Y4, Y4
	VPXOR   Y11, Y5, Y5
	VPXOR   Y8, Y6, Y6
	VPXOR   Y9, Y0, Y0
	VMOVDQU Y7, (SP)
	VPSRLD  $0x0c, Y4, Y7
	VPSLLD  $0x14, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x0c, Y5, Y7
	VPSLLD  $0x14, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x0c, Y6, Y7
	VPSLLD  $0x14, Y6, Y6
	VPOR    Y7, Y6, Y6
	VPSRLD  $0x0c, Y0, Y7
	VPSLLD  $0x14, Y0, Y0
	VPOR    Y7, Y0, Y0
	VMOVDQU (SP), Y7
	VPADDD  (CX), Y7, Y7
	VPADDD  64(CX), Y1, Y1
	VPADDD  256(CX), Y2, Y2
	VPADDD  192(CX), Y3, Y3
	VPADDD  Y4, Y7, Y7
	VPADDD  Y5, Y1, Y1
	VPADDD  Y6, Y2, Y2
	VPADDD  Y0, Y3, Y3
	VPXOR   Y7, Y15, Y15
	VPXOR   Y1, Y12, Y12
	VPXOR   Y2, Y13, Y13
	VPXOR   Y3, Y14, Y14
	VPSHUFB rot8_shuf<>+0(SB), Y15, Y15
	VPSHUFB rot8_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot8_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot8_shuf<>+0(SB), Y14, Y14
	VPADDD  Y15, Y10, Y10
	VPADDD  Y12, Y11, Y11
	VPADDD  Y13, Y8, Y8
	VPADDD  Y14, Y9, Y9
	VPXOR   Y10, Y4, Y4
	VPXOR   Y11, Y5, Y5
	VPXOR   Y8, Y6, Y6
	VPXOR   Y9, Y0, Y0
	VMOVDQU Y7, (SP)
	VPSRLD  $0x07, Y4, Y7
	VPSLLD  $0x19, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x07, Y5, Y7
	VPSLLD  $0x19, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x07, Y6, Y7
	VPSLLD  $0x19, Y6, Y6
	VPOR    Y7, Y6, Y6
	VPSRLD  $0x07, Y0, Y7
	VPSLLD  $0x19, Y0, Y0
	VPOR    Y7, Y0, Y0
	VMOVDQU (SP), Y7
	VPADDD  384(CX), Y7, Y7
	VPADDD  288(CX), Y1, Y1
	VPADDD  480(CX), Y2, Y2
	VPADDD  448(CX), Y3, Y3
	VPADDD  Y0, Y7, Y7
	VPADDD  Y4, Y1, Y1
	VPADDD  Y5, Y2, Y2
	VPADDD  Y6, Y3, Y3
	VPXOR   Y7, Y12, Y12
	VPXOR   Y1, Y13, Y13
	VPXOR   Y2, Y14, Y14
	VPXOR   Y3, Y15, Y15
	VPSHUFB rot16_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot16_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot16_shuf<>+0(SB), Y14, Y14
	VPSHUFB rot16_shuf<>+0(SB), Y15, Y15
	VPADDD  Y12, Y8, Y8
	VPADDD  Y13, Y9, Y9
	VPADDD  Y14, Y10, Y10
	VPADDD  Y15, Y11, Y11
	VPXOR   Y8, Y0, Y0
	VPXOR   Y9, Y4, Y4
	VPXOR   Y10, Y5, Y5
	VPXOR   Y11, Y6, Y6
	VMOVDQU Y7, (SP)
	VPSRLD  $0x0c, Y0, Y7
	VPSLLD  $0x14, Y0, Y0
	VPOR    Y7, Y0, Y0
	VPSRLD  $0x0c, Y4, Y7
	VPSLLD  $0x14, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x0c, Y5, Y7
	VPSLLD  $0x14, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x0c, Y6, Y7
	VPSLLD  $0x14, Y6, Y6
	VPOR    Y7, Y6, Y6
	VMOVDQU (SP), Y7
	VPADDD  416(CX), Y7, Y7
	VPADDD  352(CX), Y1, Y1
	VPADDD  320(CX), Y2, Y2
	VPADDD  256(CX), Y3, Y3
	VPADDD  Y0, Y7, Y7
	VPADDD  Y4, Y1, Y1
	VPADDD  Y5, Y2, Y2
	VPADDD  Y6, Y3, Y3
	VPXOR   Y7, Y12, Y12
	VPXOR   Y1, Y13, Y13
	VPXOR   Y2, Y14, Y14
	VPXOR   Y3, Y15, Y15
	VPSHUFB rot8_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot8_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot8_shuf<>+0(SB), Y14, Y14
	VPSHUFB rot8_shuf<>+0(SB), Y15, Y15
	VPADDD  Y12, Y8, Y8
	VPADDD  Y13, Y9, Y9
	VPADDD  Y14, Y10, Y10
	VPADDD  Y15, Y11, Y11
	VPXOR   Y8, Y0, Y0
	VPXOR   Y9, Y4, Y4
	VPXOR   Y10, Y5, Y5
	VPXOR   Y11, Y6, Y6
	VMOVDQU Y7, (SP)
	VPSRLD  $0x07, Y0, Y7
	VPSLLD  $0x19, Y0, Y0
	VPOR    Y7, Y0, Y0
	VPSRLD  $0x07, Y4, Y7
	VPSLLD  $0x19, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x07, Y5, Y7
	VPSLLD  $0x19, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x07, Y6, Y7
	VPSLLD  $0x19, Y6, Y6
	VPOR    Y7, Y6, Y6
	VMOVDQU (SP), Y7
	VPADDD  224(CX), Y7, Y7
	VPADDD  160(CX), Y1, Y1
	VPADDD  (CX), Y2, Y2
	VPADDD  192(CX), Y3, Y3
	VPADDD  Y4, Y7, Y7
	VPADDD  Y5, Y1, Y1
	VPADDD  Y6, Y2, Y2
	VPADDD  Y0, Y3, Y3
	VPXOR   Y7, Y15, Y15
	VPXOR   Y1, Y12, Y12
	VPXOR   Y2, Y13, Y13
	VPXOR   Y3, Y14, Y14
	VPSHUFB rot16_shuf<>+0(SB), Y15, Y15
	VPSHUFB rot16_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot16_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot16_shuf<>+0(SB), Y14, Y14
	VPADDD  Y15, Y10, Y10
	VPADDD  Y12, Y11, Y11
	VPADDD  Y13, Y8, Y8
	VPADDD  Y14, Y9, Y9
	VPXOR   Y10, Y4, Y4
	VPXOR   Y11, Y5, Y5
	VPXOR   Y8, Y6, Y6
	VPXOR   Y9, Y0, Y0
	VMOVDQU Y7, (SP)
	VPSRLD  $0x0c, Y4, Y7
	VPSLLD  $0x14, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x0c, Y5, Y7
	VPSLLD  $0x14, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x0c, Y6, Y7
	VPSLLD  $0x14, Y6, Y6
	VPOR    Y7, Y6, Y6
	VPSRLD  $0x0c, Y0, Y7
	VPSLLD  $0x14, Y0, Y0
	VPOR    Y7, Y0, Y0
	VMOVDQU (SP), Y7
	VPADDD  64(CX), Y7, Y7
	VPADDD  96(CX), Y1, Y1
	VPADDD  32(CX), Y2, Y2
	VPADDD  128(CX), Y3, Y3
	VPADDD  Y4, Y7, Y7
	VPADDD  Y5, Y1, Y1
	VPADDD  Y6, Y2, Y2
	VPADDD  Y0, Y3, Y3
	VPXOR   Y7, Y15, Y15
	VPXOR   Y1, Y12, Y12
	VPXOR   Y2, Y13, Y13
	VPXOR   Y3, Y14, Y14
	VPSHUFB rot8_shuf<>+0(SB), Y15, Y15
	VPSHUFB rot8_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot8_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot8_shuf<>+0(SB), Y14, Y14
	VPADDD  Y15, Y10, Y10
	VPADDD  Y12, Y11, Y11
	VPADDD  Y13, Y8, Y8
	VPADDD  Y14, Y9, Y9
	VPXOR   Y10, Y4, Y4
	VPXOR   Y11, Y5, Y5
	VPXOR   Y8, Y6, Y6
	VPXOR   Y9, Y0, Y0
	VMOVDQU Y7, (SP)
	VPSRLD  $0x07, Y4, Y7
	VPSLLD  $0x19, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x07, Y5, Y7
	VPSLLD  $0x19, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x07, Y6, Y7
	VPSLLD  $0x19, Y6, Y6
	VPOR    Y7, Y6, Y6
	VPSRLD  $0x07, Y0, Y7
	VPSLLD  $0x19, Y0, Y0
	VPOR    Y7, Y0, Y0
	VMOVDQU (SP), Y7
	VPADDD  288(CX), Y7, Y7
	VPADDD  352(CX), Y1, Y1
	VPADDD  256(CX), Y2, Y2
	VPADDD  480(CX), Y3, Y3
	VPADDD  Y0, Y7, Y7
	VPADDD  Y4, Y1, Y1
	VPADDD  Y5, Y2, Y2
	VPADDD  Y6, Y3, Y3
	VPXOR   Y7, Y12, Y12
	VPXOR   Y1, Y13, Y13
	VPXOR   Y2, Y14, Y14
	VPXOR   Y3, Y15, Y15
	VPSHUFB rot16_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot16_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot16_shuf<>+0(SB), Y14, Y14
	VPSHUFB rot16_shuf<>+0(SB), Y15, Y15
	VPADDD  Y12, Y8, Y8
	VPADDD  Y13, Y9, Y9
	VPADDD  Y14, Y10, Y10
	VPADDD  Y15, Y11, Y11
	VPXOR   Y8, Y0, Y0
	VPXOR   Y9, Y4, Y4
	VPXOR   Y10, Y5, Y5
	VPXOR   Y11, Y6, Y6
	VMOVDQU Y7, (SP)
	VPSRLD  $0x0c, Y0, Y7
	VPSLLD  $0x14, Y0, Y0
	VPOR    Y7, Y0, Y0
	VPSRLD  $0x0c, Y4, Y7
	VPSLLD  $0x14, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x0c, Y5, Y7
	VPSLLD  $0x14, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x0c, Y6, Y7
	VPSLLD  $0x14, Y6, Y6
	VPOR    Y7, Y6, Y6
	VMOVDQU (SP), Y7
	VPADDD  448(CX), Y7, Y7
	VPADDD  160(CX), Y1, Y1
	VPADDD  384(CX), Y2, Y2
	VPADDD  32(CX), Y3, Y3
	VPADDD  Y0, Y7, Y7
	VPADDD  Y4, Y1, Y1
	VPADDD  Y5, Y2, Y2
	VPADDD  Y6, Y3, Y3
	VPXOR   Y7, Y12, Y12
	VPXOR   Y1, Y13, Y13
	VPXOR   Y2, Y14, Y14
	VPXOR   Y3, Y15, Y15
	VPSHUFB rot8_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot8_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot8_shuf<>+0(SB), Y14, Y14
	VPSHUFB rot8_shuf<>+0(SB), Y15, Y15
	VPADDD  Y12, Y8, Y8
	VPADDD  Y13, Y9, Y9
	VPADDD  Y14, Y10, Y10
	VPADDD  Y15, Y11, Y11
	VPXOR   Y8, Y0, Y0
	VPXOR   Y9, Y4, Y4
	VPXOR   Y10, Y5, Y5
	VPXOR   Y11, Y6, Y6
	VMOVDQU Y7, (SP)
	VPSRLD  $0x07, Y0, Y7
	VPSLLD  $0x19, Y0, Y0
	VPOR    Y7, Y0, Y0
	VPSRLD  $0x07, Y4, Y7
	VPSLLD  $0x19, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x07, Y5, Y7
	VPSLLD  $0x19, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x07, Y6, Y7
	VPSLLD  $0x19, Y6, Y6
	VPOR    Y7, Y6, Y6
	VMOVDQU (SP), Y7
	VPADDD  416(CX), Y7, Y7
	VPADDD  (CX), Y1, Y1
	VPADDD  64(CX), Y2, Y2
	VPADDD  128(CX), Y3, Y3
	VPADDD  Y4, Y7, Y7
	VPADDD  Y5, Y1, Y1
	VPADDD  Y6, Y2, Y2
	VPADDD  Y0, Y3, Y3
	VPXOR   Y7, Y15, Y15
	VPXOR   Y1, Y12, Y12
	VPXOR   Y2, Y13, Y13
	VPXOR   Y3, Y14, Y14
	VPSHUFB rot16_shuf<>+0(SB), Y15, Y15
	VPSHUFB rot16_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot16_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot16_shuf<>+0(SB), Y14, Y14
	VPADDD  Y15, Y10, Y10
	VPADDD  Y12, Y11, Y11
	VPADDD  Y13, Y8, Y8
	VPADDD  Y14, Y9, Y9
	VPXOR   Y10, Y4, Y4
	VPXOR   Y11, Y5, Y5
	VPXOR   Y8, Y6, Y6
	VPXOR   Y9, Y0, Y0
	VMOVDQU Y7, (SP)
	VPSRLD  $0x0c, Y4, Y7
	VPSLLD  $0x14, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x0c, Y5, Y7
	VPSLLD  $0x14, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x0c, Y6, Y7
	VPSLLD  $0x14, Y6, Y6
	VPOR    Y7, Y6, Y6
	VPSRLD  $0x0c, Y0, Y7
	VPSLLD  $0x14, Y0, Y0
	VPOR    Y7, Y0, Y0
	VMOVDQU (SP), Y7
	VPADDD  96(CX), Y7, Y7
	VPADDD  320(CX), Y1, Y1
	VPADDD  192(CX), Y2, Y2
	VPADDD  224(CX), Y3, Y3
	VPADDD  Y4, Y7, Y7
	VPADDD  Y5, Y1, Y1
	VPADDD  Y6, Y2, Y2
	VPADDD  Y0, Y3, Y3
	VPXOR   Y7, Y15, Y15
	VPXOR   Y1, Y12, Y12
	VPXOR   Y2, Y13, Y13
	VPXOR   Y3, Y14, Y14
	VPSHUFB rot8_shuf<>+0(SB), Y15, Y15
	VPSHUFB rot8_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot8_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot8_shuf<>+0(SB), Y14, Y14
	VPADDD  Y15, Y10, Y10
	VPADDD  Y12, Y11, Y11
	VPADDD  Y13, Y8, Y8
	VPADDD  Y14, Y9, Y9
	VPXOR   Y10, Y4, Y4
	VPXOR   Y11, Y5, Y5
	VPXOR   Y8, Y6, Y6
	VPXOR   Y9, Y0, Y0
	VMOVDQU Y7, (SP)
	VPSRLD  $0x07, Y4, Y7
	VPSLLD  $0x19, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x07, Y5, Y7
	VPSLLD  $0x19, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x07, Y6, Y7
	VPSLLD  $0x19, Y6, Y6
	VPOR    Y7, Y6, Y6
	VPSRLD  $0x07, Y0, Y7
	VPSLLD  $0x19, Y0, Y0
	VPOR    Y7, Y0, Y0
	VMOVDQU (SP), Y7
	VPADDD  352(CX), Y7, Y7
	VPADDD  160(CX), Y1, Y1
	VPADDD  32(CX), Y2, Y2
	VPADDD  256(CX), Y3, Y3
	VPADDD  Y0, Y7, Y7
	VPADDD  Y4, Y1, Y1
	VPADDD  Y5, Y2, Y2
	VPADDD  Y6, Y3, Y3
	VPXOR   Y7, Y12, Y12
	VPXOR   Y1, Y13, Y13
	VPXOR   Y2, Y14, Y14
	VPXOR   Y3, Y15, Y15
	VPSHUFB rot16_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot16_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot16_shuf<>+0(SB), Y14, Y14
	VPSHUFB rot16_shuf<>+0(SB), Y15, Y15
	VPADDD  Y12, Y8, Y8
	VPADDD  Y13, Y9, Y9
	VPADDD  Y14, Y10, Y10
	VPADDD  Y15, Y11, Y11
	VPXOR   Y8, Y0, Y0
	VPXOR   Y9, Y4, Y4
	VPXOR   Y10, Y5, Y5
	VPXOR   Y11, Y6, Y6
	VMOVDQU Y7, (SP)
	VPSRLD  $0x0c, Y0, Y7
	VPSLLD  $0x14, Y0, Y0
	VPOR    Y7, Y0, Y0
	VPSRLD  $0x0c, Y4, Y7
	VPSLLD  $0x14, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x0c, Y5, Y7
	VPSLLD  $0x14, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x0c, Y6, Y7
	VPSLLD  $0x14, Y6, Y6
	VPOR    Y7, Y6, Y6
	VMOVDQU (SP), Y7
	VPADDD  480(CX), Y7, Y7
	VPADDD  (CX), Y1, Y1
	VPADDD  288(CX), Y2, Y2
	VPADDD  192(CX), Y3, Y3
	VPADDD  Y0, Y7, Y7
	VPADDD  Y4, Y1, Y1
	VPADDD  Y5, Y2, Y2
	VPADDD  Y6, Y3, Y3
	VPXOR   Y7, Y12, Y12
	VPXOR   Y1, Y13, Y13
	VPXOR   Y2, Y14, Y14
	VPXOR   Y3, Y15, Y15
	VPSHUFB rot8_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot8_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot8_shuf<>+0(SB), Y14, Y14
	VPSHUFB rot8_shuf<>+0(SB), Y15, Y15
	VPADDD  Y12, Y8, Y8
	VPADDD  Y13, Y9, Y9
	VPADDD  Y14, Y10, Y10
	VPADDD  Y15, Y11, Y11
	VPXOR   Y8, Y0, Y0
	VPXOR   Y9, Y4, Y4
	VPXOR   Y10, Y5, Y5
	VPXOR   Y11, Y6, Y6
	VMOVDQU Y7, (SP)
	VPSRLD  $0x07, Y0, Y7
	VPSLLD  $0x19, Y0, Y0
	VPOR    Y7, Y0, Y0
	VPSRLD  $0x07, Y4, Y7
	VPSLLD  $0x19, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x07, Y5, Y7
	VPSLLD  $0x19, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x07, Y6, Y7
	VPSLLD  $0x19, Y6, Y6
	VPOR    Y7, Y6, Y6
	VMOVDQU (SP), Y7
	VPADDD  448(CX), Y7, Y7
	VPADDD  64(CX), Y1, Y1
	VPADDD  96(CX), Y2, Y2
	VPADDD  224(CX), Y3, Y3
	VPADDD  Y4, Y7, Y7
	VPADDD  Y5, Y1, Y1
	VPADDD  Y6, Y2, Y2
	VPADDD  Y0, Y3, Y3
	VPXOR   Y7, Y15, Y15
	VPXOR   Y1, Y12, Y12
	VPXOR   Y2, Y13, Y13
	VPXOR   Y3, Y14, Y14
	VPSHUFB rot16_shuf<>+0(SB), Y15, Y15
	VPSHUFB rot16_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot16_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot16_shuf<>+0(SB), Y14, Y14
	VPADDD  Y15, Y10, Y10
	VPADDD  Y12, Y11, Y11
	VPADDD  Y13, Y8, Y8
	VPADDD  Y14, Y9, Y9
	VPXOR   Y10, Y4, Y4
	VPXOR   Y11, Y5, Y5
	VPXOR   Y8, Y6, Y6
	VPXOR   Y9, Y0, Y0
	VMOVDQU Y7, (SP)
	VPSRLD  $0x0c, Y4, Y7
	VPSLLD  $0x14, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x0c, Y5, Y7
	VPSLLD  $0x14, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x0c, Y6, Y7
	VPSLLD  $0x14, Y6, Y6
	VPOR    Y7, Y6, Y6
	VPSRLD  $0x0c, Y0, Y7
	VPSLLD  $0x14, Y0, Y0
	VPOR    Y7, Y0, Y0
	VMOVDQU (SP), Y7
	VPADDD  320(CX), Y7, Y7
	VPADDD  384(CX), Y1, Y1
	VPADDD  128(CX), Y2, Y2
	VPADDD  416(CX), Y3, Y3
	VPADDD  Y4, Y7, Y7
	VPADDD  Y5, Y1, Y1
	VPADDD  Y6, Y2, Y2
	VPADDD  Y0, Y3, Y3
	VPXOR   Y7, Y15, Y15
	VPXOR   Y1, Y12, Y12
	VPXOR   Y2, Y13, Y13
	VPXOR   Y3, Y14, Y14
	VPSHUFB rot8_shuf<>+0(SB), Y15, Y15
	VPSHUFB rot8_shuf<>+0(SB), Y12, Y12
	VPSHUFB rot8_shuf<>+0(SB), Y13, Y13
	VPSHUFB rot8_shuf<>+0(SB), Y14, Y14
	VPADDD  Y15, Y10, Y10
	VPADDD  Y12, Y11, Y11
	VPADDD  Y13, Y8, Y8
	VPADDD  Y14, Y9, Y9
	VPXOR   Y10, Y4, Y4
	VPXOR   Y11, Y5, Y5
	VPXOR   Y8, Y6, Y6
	VPXOR   Y9, Y0, Y0
	VMOVDQU Y7, (SP)
	VPSRLD  $0x07, Y4, Y7
	VPSLLD  $0x19, Y4, Y4
	VPOR    Y7, Y4, Y4
	VPSRLD  $0x07, Y5, Y7
	VPSLLD  $0x19, Y5, Y5
	VPOR    Y7, Y5, Y5
	VPSRLD  $0x07, Y6, Y7
	VPSLLD  $0x19, Y6, Y6
	VPOR    Y7, Y6, Y6
	VPSRLD  $0x07, Y0, Y7
	VPSLLD  $0x19, Y0, Y0
	VPOR    Y7, Y0, Y0
	VMOVDQU (SP), Y7
	VMOVDQU Y7, (AX)
	VMOVDQU Y1, 32(AX)
	VMOVDQU Y2, 64(AX)
	VMOVDQU Y3, 96(AX)
	VMOVDQU Y0, 128(AX)
	VMOVDQU Y4, 160(AX)
	VMOVDQU Y5, 192(AX)
	VMOVDQU Y6, 224(AX)
	VMOVDQU Y8, 256(AX)
	VMOVDQU Y9, 288(AX)
	VMOVDQU Y10, 320(AX)
	VMOVDQU Y11, 352(AX)
	VMOVDQU Y12, 384(AX)
	VMOVDQU Y13, 416(AX)
	VMOVDQU Y14, 448(AX)
	VMOVDQU Y15, 480(AX)
	RET
